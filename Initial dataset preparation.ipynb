{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set the right directory\n",
    "#### Need to put in C drive since R-drive cannot hold big file!\n",
    "\n",
    "%cd \"C:\\GfK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c599e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Pandas to read in the csv files\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d55bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We read in the CSV file with all the FMCG expenditures in the 2nd half of 2020\n",
    "### The file is to big to make a copy so we just do the operations right the first time\n",
    "df0 = pd.read_csv('Kaufinformationen_FMCG_2020.csv)\n",
    "                  \n",
    "### We set that the first row is actually the set of columns we want to use\n",
    "df0.columns = df0.iloc[0]\n",
    "df0 = df.reindex(df0.index.drop(0)).reset_index(drop=True)\n",
    "df0.columns.name = None\n",
    "\n",
    "### We merge this information from each expenditure record with the associated background characteristics\n",
    "### of the household. We use a left join on the household identifier key, hhkey, that is common to both\n",
    "### dataframes as there is a many to one relationship on the hhkey and it makes sense to then use a left join                  \n",
    "df = df0.merge('Haushaltsinformationen_FMCG_2020', how='left', on='hhkey', indicator = True)\n",
    "\n",
    "### Set condition that we only want to keep all expenditure records that are in both dataframes and merged\n",
    "### successfully, hence we use the '_merge' column and specify that we want the records where _merge=='both'\n",
    "in_both_df = df['_merge'] == 'both'\n",
    "\n",
    "### Filter the dataframe with the 'in_both_df' condition above\n",
    "df = df.loc[in_both_df]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e963f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Before we go further, we modify the dates in our dataframe. The 'datum' column ('datum' is date in German)\n",
    "### is of the form YYYYMMDD so we extract all the relevant information to make the time dimension in our dataframe\n",
    "### useful for analysis later\n",
    "\n",
    "### Create a new column called 'datevar' that takes the 'datum' and converts the entries into a Pandas date time column\n",
    "df['datevar'] = pd.to_datetime(df['datum'], format = \"%Y%m%d\")\n",
    "\n",
    "### Now we can easily extract the Year, Month, Week and Day columns from the 'datevar' column described above\n",
    "df['Year'] = df['datevar'].dt.strftime('%Y')\n",
    "df['Month'] = df['datevar'].dt.strftime('%m')\n",
    "df['Week'] = pd.to_datetime(df['datevar']).dt.isocalendar().week\n",
    "df['Day'] = df['datevar'].dt.strftime('%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e632540",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the file to be used in the next step\n",
    "pd.to_csv('finaldata_FMCG_2020.csv', index_col = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
