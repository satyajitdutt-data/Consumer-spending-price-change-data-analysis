{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set the right directory\n",
    "#### Need to put in C drive since R-drive cannot hold big file!\n",
    "\n",
    "%cd \"C:\\GfK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import NumPy and Pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef728794",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to merge the data from the FMCG_1920 file where we computed the price index for each household \n",
    "### where we have 1 record per household to that were linked to the special GfK commissioned survey administered\n",
    "### in early 2021\n",
    "\n",
    "### Read in the FMCG_1920 file\n",
    "fmcg_1920 = pd.read_csv('FMCG_1920.csv')\n",
    "\n",
    "### Merge it with the GfK survey_file\n",
    "fmcg_gfk = fmcg_1920.merge('GfK_Survey_1_2021', how='inner', on='hhkey', indicator = True)\n",
    "\n",
    "### Set condition that we only want household records in both dataframes (the column hhkey exists in both dataframes)\n",
    "inner_join = fmcg_gfk['_merge'] == 'both'\n",
    "\n",
    "### Drop all records not in both dataframes from the condition above\n",
    "fmcg_gfk = fmcg_gfk.loc[inner_join]\n",
    "\n",
    "### Create a copy of the final dataframe that we will use in our analysis\n",
    "df = fmcg_gfk.copy(:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3291a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The non-durable and durable consumption columns for the 2nd half of 2020, f04b and f05c, are string columns.\n",
    "### Let us make it a float valued columns\n",
    "\n",
    "''' This function basically converts any empty space strings to a nan \n",
    "    and any string valued non-missing entry to a float '''\n",
    "\n",
    "def tonum(x):\n",
    "    \n",
    "    if ' ' in x:\n",
    "        a = np.nan\n",
    "        return a\n",
    "    else:\n",
    "        a = float(x)\n",
    "        return a\n",
    "\n",
    "### Use the apply method to convert it to a float valued column\n",
    "df['nondur_past_month'] = df['f04b'].apply(tonum)\n",
    "df['ldur_2_euro'] = df['f05c'].apply(tonum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The net income column 'hhnetto' is defined as a string column and coded as income brackets\n",
    "### i.e. If a household has a monthly net income of 3500, then as we do not receive not get the exact value in the survey, \n",
    "### it is coded in as being in the '3000 Euro - 5000 Euro' category. For these values we take the midpoint of the income bracket above so in this case, 4000 \n",
    "### The lowest net income category is coded as 'bis 499 Euro' (upto 499 Euros). We give these values 249.5, 0.5*(0 + 499)\n",
    "### The highest net income category is coded as '5000 Euro und mehr' (5000 Euros or more), We give these values 7500\n",
    "\n",
    "### Define a function to perform the operation above \n",
    "def new_income(x):\n",
    "    ### We can detect any record with a bracketed income category as having a '-' in the entry. The lowest and highest income\n",
    "    ### categories do not have it, so it easily identifies these values. \n",
    "    ### Thus if we have an income bracket'a Euro - b Euro', We want to isolate a and b and take the simple mean to compute\n",
    "    ### the monthly household income. \n",
    "    if '-' in x:\n",
    "        y = x.replace('Euro','').replace('  ','').replace('- ','-')\n",
    "    ### We chain 3 operations using the replace method s.t we are left with 'a-b' and use the split method and convert those\n",
    "    ### values to a float and take the simple mean\n",
    "        a,b = y.split('-')\n",
    "        return 0.5*(float(a) + float(b))\n",
    "    ### The top income category is '5000 Euro und mehr' so we just look for entries with 'und mehr' and set those entries to \n",
    "    ### a float value of 7500\n",
    "    elif 'und mehr' in x:\n",
    "        return float(7500)\n",
    "    ### The lowest income category is the only one left and we just set those to a float value odf 249.5\n",
    "    else: \n",
    "        return float(249.5)\n",
    "\n",
    "### Use the apply method to our new column called 'hhinc_cont' for continuous valued net income\n",
    "df['hhinc_cont'] = df['hhnetto'].apply(new_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fd05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Our non-durable consumption column created above, 'nondur_past_month' is defined as a monthly amount\n",
    "### Our netincome is also defined at a monthly level\n",
    "\n",
    "### As we want to look at the impact of our VAT perception on non-durable consumption later, we want to keep \n",
    "### only reasonable values in our dataframe. To first do that, we compute the percentage of non-durable consumption\n",
    "### to net income, C/Y\n",
    "\n",
    "df['ratio_nondur_y'] =  df['nondur_past_month']/df['hhinc_cont']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ad6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We set 2 restrictions that any household's non-durable consumption should comply with in order to stay\n",
    "### as valid records in our dataframe\n",
    "\n",
    "### 'restriction_1' is about the ratio of non-durable consumption to income as defined above, 'ratio_nondur_y'. We stipulate the restriction\n",
    "### that this ratio must be greater than 0, defined as 'min_ratio' below and less than 150%, defined as 'max_ratio' below\n",
    "\n",
    "### We pass in a list of 2 new columns with the values described above \n",
    "df[['min_ratio','max_ratio']] = [0,1.5]\n",
    "\n",
    "### The first part of the restriction identifies household records where the ratio is less than 0 and non-missing\n",
    "### The second part of the restriction identifies household records where the ratio is greater than 1.5 and non-missing\n",
    "restriction_1 = ((df['ratio_nondur_y'] < df['min_ratio']) & (df['ratio_nondur_y'].notna())|df['ratio_nondur_y'] > df['max_ratio']) & (df['ratio_nondur_y'].notna())\n",
    "\n",
    "### 'restriction_2' is about the level of monthly non-durable consumption as defined in the column, 'nondur_past_month'. \n",
    "### We stipulate the restriction that the minimum monthly level should be creater than 1000, defined as 'min_cons' below \n",
    "### and less than 10000, defined as 'max_cons' below\n",
    "\n",
    "### We pass in a list of 2 new columns with the values shown above \n",
    "df[['min_cons','max_cons']] = [100,10000]\n",
    "\n",
    "### The first part of the restriction identifies household records where the non-durable consumption level is less than 100 and non-missing\n",
    "### The first part of the restriction identifies household records where the non-durable consumption level is greater than 10000 and non-missing\n",
    "restriction_2 = (df['nondur_past_month'] > df['max_cons']) & (df['nondur_past_month'].notna())|(df['nondur_past_month']< df['min_cons']) & (df['nondur_past_month'].notna())\n",
    "\n",
    "### Drop the household records that do not satisfy the ratio restriction, 'restriction_1'\n",
    "df = df[~restriction_1]\n",
    "\n",
    "### Drop the household records that do not satisfy the level restriction, 'restriction_1'\n",
    "df = df[~restriction_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We want to see the effect of the VAT-perception on non-durable consumption in the 2nd half of 2020\n",
    "### As our column 'nondur_past_month' is defined in monthly terms, we need to multiply this value by 6 \n",
    "### so that it represents non-durable consumption for the 2nd half of 2020 and we define it as a new \n",
    "### column called 'nondur_2_euro' below\n",
    "df['nondur_2_euro'] = df['nondur_past_month']*6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e06f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Our key column that we want to see the effect on 2020 2nd half non-durable consumption is the perception of how prices\n",
    "### fell in the 2nd half of 2020, when the German government announced the VAT (Value-Added Tax) cut of 3% from \n",
    "### July 1, 2020 to December 31, 2020. The Dutch translation is 'Omzetbelasting' (btw)\n",
    "\n",
    "### The original column is called 'f07' which is a categorical column with 6 non-missing categories about the fall in prices\n",
    "### 'f07' has object valued entries defined below in German and there is an English translation\n",
    "\n",
    "# 1) 'Die Preise sind um mehr als 3% gesunken\" (Prices fell by more than 3%)\n",
    "# 2) 'Die Preise sind um 3% gesunken\" (Prices fell by 3%)\n",
    "# 3) 'Die Preise sind um 2% bis 3% gesunken' (Prices fell by 2-3%)\n",
    "# 4) 'Die Preise sind um weniger als 2% gesunken' (Prices fell by less than 2%)\n",
    "# 5) 'Die Preise sind gleichgeblieben' (Prices stayed the same)\n",
    "# 6) 'Die Preise sind gestiegen' (Prices rose)\n",
    "\n",
    "### We want to create a new categorical column with numerical categories from 1 to 6 as defined above\n",
    "\n",
    "### Let us define a dictionary where the key is the original object entry where the key is the \n",
    "### object entry from the original column 'f07' and the value is the number as defined above from 1 to 6\n",
    "### and the missing values are NaN\n",
    "\n",
    "vat_values = {'Die Preise sind um mehr als 3% gesunken':1, \n",
    "              'Die Preise sind um 3% gesunken':2,\n",
    "              'Die Preise sind um 2% bis 3% gesunken':3,\n",
    "              'Die Preise sind um weniger als 2% gesunken':4,\n",
    "              'Die Preise sind gleichgeblieben':5,\n",
    "              'Die Preise sind gestiegen':6,\n",
    "              ' ':np.nan}\n",
    "\n",
    "### We define the key column called 'vat_passthrough' where we apply the dictionary 'vat_values' above\n",
    "df['vat_passthrough'] = df['f07'].replace(vat_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "### One of the key features that we will use in the regression analysis below is called 'VAT_PT_b1'\n",
    "### which is a binary indicator valued column that takes a value of 0 if the column created above\n",
    "### 'vat_passthrough' takes on the categories 1-4 which basically captures those households that\n",
    "### perceived prices to have fallen in the 2nd half of 2020. The complement consists of the categories\n",
    "### who perceived prices to have stayed the same or rose in the 2nd half of 2020\n",
    "\n",
    "df.loc[df.vat_passthrough.isna(), 'VAT_PT_b1'] = np.nan\n",
    "df.loc[df.vat_passthrough <=4, 'VAT_PT_b1'] = 1\n",
    "df.loc[df.vat_passthrough >4, 'VAT_PT_b1'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a 2nd version of the key feature above as 'VAT_PT_b2' which is a binary indicator valued \n",
    "### column that takes a value of 0 if the column created above 'vat_passthrough' takes on the categories 1-3 \n",
    "### which basically captures those households that perceived prices to have fallen by at least 2% in the 2nd half of 2020. \n",
    "### The complement consists of the categories who perceived prices to fallen by less than %, stayed the same or rose \n",
    "### in the 2nd half of 2020\n",
    "\n",
    "df.loc[df.vat_passthrough.isna(), 'VAT_PT_b2'] = np.nan\n",
    "df.loc[df.vat_passthrough <=3, 'VAT_PT_b2'] = 1\n",
    "df.loc[df.vat_passthrough >3, 'VAT_PT_b2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13141c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a 3nd version of the key feature above as 'VAT_PT_mint' where we define a numerical value for how much prices\n",
    "### were perceived to have fallen for each of the 6 categoies that could have been chosen by the household in the \n",
    "### 'vat_passthrough' column.\n",
    "\n",
    "### For category 1 where 'Prices fell by more than 3%' that prices fell by 3.5%\n",
    "### For category 2 where 'Prices fell by more than 3%' that prices fell by 3%\n",
    "### For category 3 where 'Prices fell by more than 3%' that prices fell by 2.5%\n",
    "### For category 4 where 'Prices fell by more than 3%' that prices fell by 1.5%\n",
    "### For category 5 where 'Prices fell by more than 3%' that prices did not change, 0% \n",
    "### For category 6 where 'Prices fell by more than 3%' that prices rose by 1%\n",
    "\n",
    "### We define the numerical values for categories 1-4 to be the amount prices fell by (so 2 represents 2% fall)\n",
    "### so the 6th category which represnts prices rising (so -1 represents a 1% rise)\n",
    "\n",
    "### We pass a list of the corresponding categories from category 1 to 6\n",
    "values_mint = [3.5,3,2.5,1.5,0,-1]\n",
    "\n",
    "### Set the missing values to NaN\n",
    "df.loc[df.vat_passthrough.isna(), 'VAT_PT_mint'] = np.nan\n",
    "\n",
    "### Use a loop which assigns the corresponding value from the 'vat_passthrough' column\n",
    "### to the values defined above. Note since the loop index starts at 0, we need to put i+1 as the \n",
    "### vat_passthrough column starts at 1 but then for the corresponding value from the 'values_mint'\n",
    "### list we want to make sure we extract the correct index so that is indexed with by i\n",
    "\n",
    "for i in range(len(values_mint)):\n",
    "    df.loc[df.vat_passthrough == i + 1, 'VAT_PT_mint'] = values_mint[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a58a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For our target, we apply the inverse hyperbolic sine transformation to our non-durable and durable\n",
    "### consumption columns. Note that it is not unrealistic to have 0 consumption for durable consumption\n",
    "### as these purchases could include cars, and other big ticket items which are not regular purchases\n",
    "### so we do not want to exclude them if we used a logarithmic transformation\n",
    "\n",
    "df['ldur_2_euro_ihs'] = np.arcsinh(df['ldur_2_euro'])\n",
    "df['ndur_2_euro_ihs'] = np.arcsinh(df['nondur_2_euro'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d0f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we want to create some additional features that can be used in our regressions\n",
    "### The first is a binary indicator column, 'D_hhinc_low', which takes the value of 1\n",
    "### if the monthly net income is lower than the median for our sample and 0 if it is \n",
    "### equal to or above the median\n",
    "\n",
    "### First compute the median\n",
    "df['hhinc_med'] = df['hhinc_cont'].median()\n",
    "\n",
    "### Create the 'D_hhinc_low' binary indicator column\n",
    "df.loc[df.hhinc_cont.isna(), 'D_hhinc_low'] = np.nan\n",
    "df.loc[df.hhinc_cont < df.hhinc_med, 'D_hhinc_low'] = 1\n",
    "df.loc[df.hhinc_cont >= df.hhinc_med, 'D_hhinc_low'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db463697",
   "metadata": {},
   "outputs": [],
   "source": [
    "### As we did above with the original net income categories, we have a net-wealth category \n",
    "### which is also bracketed (i.e. 100000 is coded as '50.000 bis unter 15000.000' (50,000 upto but under 150,000))\n",
    "### where we compute the simple mean between the lowest and highest values in the net wealth bracket\n",
    "\n",
    "## There are 4 types of categories coded as object valued text entries\n",
    "## 1) 'ich mÃ¶chte diese Frage nicht beantworten' (I do not want to answer this question)\n",
    "## 2) 'a bis unter b â\\x82¬'' (a upto but under b)\n",
    "## 3) 'unter 0 â\\x82¬' (less than 0)\n",
    "## 4) '500.000 â\\x82¬ und mehr' (500,000 or more)\n",
    "\n",
    "## We define a function to perform this transformation from an object valued column to a numerical valued continuous column\n",
    "## called new_wealth\n",
    "def new_wealth(x):\n",
    "    ## This lookes for any entry with the text 'Frage' and this deals with the first category mentioned above. We set these\n",
    "    ## answers to missing NaN\n",
    "    if 'Frage' in x:\n",
    "        return np.nan\n",
    "    ### We can detect any record with a bracketed income category as having a 'bis unter' in the entry.\n",
    "    elif 'bis unter' in x:\n",
    "    ### We replace the 'bis unter' string characters to '-' which is useful for the step after in splitting and \n",
    "    ### computing the simple mean defined below as we did with the net income 'hhnetto'/'hhinc_cont' columns. \n",
    "    ### We chain another couple of replace methods to remove/replace useless characters shown above and below  \n",
    "        y = x.replace(' bis unter ','-').replace(' â\\x82¬','').replace('.','')\n",
    "    ### We are then left with 'a-b' which we can use the split method and then compute the simple mean. \n",
    "    ### Note that 2,3 as asked in the survey represent 2000 and 3000 so we must multiply the whole thing by 1000\n",
    "    ### to get the correct net wealth that we want\n",
    "        a,b = y.split('-')\n",
    "        return 0.5*1000*(float(a) + float(b))\n",
    "    ## This lookes for any entry with the text 'unter 0' and we return 0 for that. What we say here is if the household\n",
    "    ## reports that they have negative net wealth, we set a minimum floor of 0\n",
    "    elif 'unter 0' in x:\n",
    "        return 0\n",
    "    ## For the remaining category, 500,000 or more, we set that to 750000\n",
    "    else:\n",
    "        return 750000\n",
    "    \n",
    "### Use the apply method to our new column called 'netwealth_cont' for continuous valued net wealth\n",
    "df['netwealth_cont'] = df['f20'].apply(new_wealth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45543415",
   "metadata": {},
   "outputs": [],
   "source": [
    "### As with the net income column, we want to create binary indicator column 'D_netwealth_low', \n",
    "### which takes the value of 1 if the net wealth is lower than the median for our sample and 0 \n",
    "### if it is equal to or above the median\n",
    "\n",
    "### First compute the median\n",
    "df['netwealth_med'] = df['netwealth_cont'].median()\n",
    "\n",
    "### Create the 'D_netwealth_low' binary indicator column\n",
    "df.loc[df.netwealth_cont.isna(), 'D_netwealth_low'] = np.nan\n",
    "df.loc[df.netwealth_cont < df.netwealth_med, 'D_netwealth_low'] = 1\n",
    "df.loc[df.netwealth_cont >= df.netwealth_med, 'D_netwealth_low'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dae977",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a gender column. We call it 'female' and it takes value 1 if the household \n",
    "### respondent answering it is a woman (weiblich in German) and 0 if it is a man (mÃ¤nnlich). \n",
    "### The 'Ã¤' set of characters is really ä\n",
    "\n",
    "df.loc[df.geschlecht_hhf.isna(), 'female'] = np.nan\n",
    "df.loc[df.geschlecht_hhf== 'weiblich', 'female'] = 1\n",
    "df.loc[df.geschlecht_hhf== 'mÃ¤nnlich', 'female'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513409a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a full time employed column\n",
    "### We call it 'empl_ft' and it takes value 1 if the household respondent is employed full time \n",
    "### and 0 if he/she is not. \n",
    "\n",
    "### By default we set the value of the column to 1\n",
    "df['empl_ft'] = 1\n",
    "\n",
    "### There are 4 categories which can be classifed as not being full time employed which are passed in as list below\n",
    "non_employed_categories = ['Erziehungsurlaub','Hausfrau','Landwirt','Lehrling','Rentner (ab 2001 incl Pension)']\n",
    "### English translations are ['Parental leave', 'Housewife', 'Farmer', 'Apprentice', 'Pensioner (from 2001....)']\n",
    "\n",
    "### We set any value from the 'beruf_hauptv' that has the category shown in the list above to 0\n",
    "df.loc[df.beruf_hauptv.isin(non_employed_categories), 'empl_ft'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0623196",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a retired column\n",
    "### We call it 'retired' and it takes value 1 if the household respondent is retired and 0 if he/she is not. \n",
    "### By default we set the value of the column to 0\n",
    "df['retired'] = 0\n",
    "\n",
    "### There is only 1 retired category as defined above for the'empl_ft' column that takes the value of 1\n",
    "### if the beruf_hauptv' takes the 'Rentner (ab 2001 incl Pension)' string valued entry\n",
    "df.loc[df.beruf_hauptv==\"Rentner (ab 2001 incl Pension)\", 'retired'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c905ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a column to capture the number of households that have children under 18\n",
    "### We call it 'Dchild' and it takes value 1 if the household respondent has children under 18 \n",
    "### and 0 if it does not.\n",
    "\n",
    "### By default we set the value of the column to 1\n",
    "df['Dchild'] = 1\n",
    "\n",
    "### There is only 1 category for 'No Children' (\"ohne Kinder\" in German) and we set those values to 0\n",
    "df.loc[df.anzahl_kinder_unter_18==\"ohne Kinder\", 'Dchild'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b150659",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create 2 columns to capture whether the household head is part  of a specific age group\n",
    "### We call them 'age_young' and it takes value 1 if the household respondent aged 44 or lower\n",
    "### and 0 otherwise. The key reference column we draw from is called 'alter_hhf' which translates \n",
    "### to age of the household head\n",
    "\n",
    "### By default, we set the 'age_young' column to 0\n",
    "df['age_young']= 0\n",
    "\n",
    "### For the categories below entered as a list, which translates to 'upto 19 years of age' and then 'a-b Jahre' where a is the \n",
    "### starting point of the age category and  b is the end point for that category\n",
    "age_young = [\"bis 19 Jahre\",\"20-24 Jahre\",\"25-29 Jahre\",\"30-34 Jahre\",\"35-39 Jahre\",\"40-44 Jahre\"]\n",
    "\n",
    "### We set the 'age_young' column to 1 for all the 'alter_hhf' categories that are in the 'age_young' list above\n",
    "df.loc[df.alter_hhf.isin(age_young), 'age_young'] = 1\n",
    "\n",
    "### We do the same as above to create a column called 'age_mid' and it takes value 1 if the household \n",
    "### respondent is aged between 45 and 59 and 0 otherwise. \n",
    "\n",
    "### By default, we set the 'age_mid' column to 0\n",
    "df['age_mid']= 0\n",
    "\n",
    "### For the categories below entered as a list, which translates to 'a-b Jahre' where a is the \n",
    "### starting point of the age category and  b is the end point for that category for the 3 eligible categories\n",
    "age_mid = [\"45-49 Jahre\",\"50-54 Jahre\",\"55-59 Jahre\"]\n",
    "\n",
    "### We set the 'age_mid' column to 1 for all the 'alter_hhf' categories that are in the 'age_mid' list above\n",
    "df.loc[df.alter_hhf.isin(age_mid), 'age_mid'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a column to capture whether the household respondent has a bachelor degree from university\n",
    "### or higher. We call this column 'educ_uni' and the key reference column we draw from is called 'schulbil_hauptv'\n",
    "### which translates \n",
    "\n",
    "### By default, we set the 'educ_uni' column to 0\n",
    "df['educ_uni']= 0\n",
    "\n",
    "### We set the 'age_mid' column to 1 for the 'schulbil_hauptv' category that is classified as those who completed\n",
    "### a bachelor's degree or completed a state examination (See https://en.wikipedia.org/wiki/Staatsexamen for more details)\n",
    "df.loc[df.schulbil_hauptv=='Fachhochschule/ Staatsexamen', 'educ_uni'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a column to capture the type of city that the household lives in, roughtly from rural to urban. This\n",
    "### is a categorical variable with 5 categories. We call this column 'citysize' and the key reference column we draw \n",
    "### from is called 'ortsgroesse'\n",
    "\n",
    "### Defie the column by default to be missing and take values 1 to 5 depending on the city size\n",
    "df['citysize'] = np.nan\n",
    "\n",
    "## There are 3 types of categories coded as object valued text entries\n",
    "## 1) 'bis 1.999 Einw' (upto 1999 inhabitants)\n",
    "## 2) 'a Einw bis b Einw' (a inhabitants upto b inhabitants)\n",
    "## 3) '1.000.000 Einw u. mehr' (1,000,000 or more inhabitants)\n",
    "\n",
    "### We define 5 different lists which define groups of city sizes\n",
    "\n",
    "### Those who live in cities that have upto 4,999 habitants which we want to eventually the 'citysize' column to 1\n",
    "citysize_1 = [\"bis 1.999 Einw\",\"2.000 Einw bis 2.999 Einw\",\"3.000 Einw bis 4.999 Einw\"] \n",
    "### Those who live in cities that are in between 5,000 to 19,999 habitants which we want to eventually the 'citysize' column to 2\n",
    "citysize_2 = [\"5.000 Einw bis 9.999 Einw\",\"10.000 Einw bis 19.999 Einw\"] \n",
    "### Those who live in cities that are in between 50,000 to 99,999 habitants which we want to eventually the 'citysize' column to 3\n",
    "citysize_3 = [\"20.000 Einw bis 49.999 Einw\",\"50.000 Einw bis  99.999 Einw\"]\n",
    "### Those who live in cities that are in between 200,000 to 299,999 habitants which we want to eventually the 'citysize' column to 4\n",
    "citysize_4 = [\"100.000 Einw bis 199.999 Einw\",\"200.000 Einw bis 299.999 Einw\"] \n",
    "### Those who live in cities with more than 500,000 inhabitants which we want to eventually the 'citysize' column to 5\n",
    "citysize_5 = [\"500.000 Einw bis 999.999 Einw\",\"1.000.000 Einw u. mehr\"] \n",
    "\n",
    "### We nest those lists above into a list called 'citysize_group'\n",
    "citysize_group = [citysize_1, citysize_2, citysize_3, citysize_4, citysize_5]\n",
    "\n",
    "### Run a loop where we set the condition that if the categories of the 'ortsgroesse' column lies in one of the 5 groups\n",
    "### listed above, then it takes that pre-defined value mentioned above. Note that the list index for 'citysize_group' starts\n",
    "### from 0 but out classification category starts at 1 so hence the need for i and i+1 to accomodate for that. This \n",
    "### creates the categorical values for the 'citysize' column\n",
    "\n",
    "for i in range(5):\n",
    "        df.loc[df.ortsgroesse.isin(citysize_group[i]), 'citysize'] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We create a column to capture which state that the household lives in, roughtly from rural to urban. This\n",
    "### is a categorical variable with 4 categories. We call this column 'State' and the key reference column we draw \n",
    "### from is called 'gebiet' which translates to 'area' in English and 'gebied' in Dutch\n",
    "\n",
    "### Defie the column by default to be missing and take values 1 to 4 depending on where the state is located.\n",
    "df['State'] = np.nan\n",
    "\n",
    "### We put the region of 'Nord', 'North' as category 1 (Northern region of Germany)\n",
    "df.loc[df.gebiet=='Nord', 'State'] = 1\n",
    "### We put the regions of 'NRW', 'Centre' as category 2 (The Western region of Germany)\n",
    "df.loc[df.gebiet.isin(['NRW','Mitte']), 'State'] = 2\n",
    "### We put the regions of 'NRW', 'Centre' as category 3 (The Southern region of Germany)\n",
    "df.loc[df.gebiet.isin(['BaWue','Bayern']), 'State'] = 3\n",
    "### We put the regions of 'Nordost','Suedost','Berlin' as category 4 (The Eastern region of Germany)\n",
    "df.loc[df.gebiet.isin(['Nordost','Suedost','Berlin']), 'State'] = 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
